{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888443c-dcab-4e8d-8edf-f3daf203da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install pinecone-client\n",
    "!pip install pypdf\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30da3d72-858f-4e62-b90c-ada8dc254e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f9f54-5857-4edc-a7ad-87fdb9966df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db721db-44b7-4789-b397-25cba340380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaderPyPDFDirectoryLoader(\"Vector/pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06407661-36a0-49b2-80a0-d973fb37c04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ca48d-3171-4ead-a214-dc08d1fb2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20247d-c045-48f4-9bfe-484b003608b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3c5c2-d740-493b-9d1a-22e9e450d04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2ff12-2806-4e0c-8fa5-9fa97e542d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6ce45-f1bc-4223-913f-6e8d164ab0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_chunks[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be599a3a-7bf3-418d-b576-26b077574244",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377bbe6-b76c-4781-9882-fe12f4d4ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "query = \"How many people live in London?\"\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "#Load the model\n",
    "model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "#Encode query and documents\n",
    "query_emb = model.encode(query)\n",
    "doc_emb = model.encode(docs)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fb293-39fa-458f-b2d4-4d9b0632a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"hkunlp/instructor-large\")\n",
    "embeddings = model.encode(\n",
    "    [\n",
    "        \"Dynamical Scalar Degree of Freedom in Horava-Lifshitz Gravity\",\n",
    "        \"Comparison of Atmospheric Neutrino Flux Calculations at Low Energies\",\n",
    "        \"Fermion Bags in the Massive Gross-Neveu Model\",\n",
    "        \"QCD corrections to Associated t-tbar-H production at the Tevatron\",\n",
    "    ],\n",
    "    prompt=\"Represent the Medicine sentence for clustering: \",\n",
    ")\n",
    "print(model.encode(\"who are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c6315-8c6d-448e-990d-d0f949e285c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get(\"PINECONE_API_KEY\", \"ace0ea59-9e7b-476c-acad-716e674eac5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032fb52-7bea-470a-a578-3b37d5cd8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone as PC\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b52aab-d66f-4e5b-b82c-e4e9502a720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc= PC(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e4cd6-bed7-43f3-baee-8f84dfed7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e841d1-b5a9-4c73-b0a4-8f09c35e64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f4bbf-11e2-4209-8684-9797278581cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256da913-7e97-4c6e-8fc5-2148e26a2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=PC.Index(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9435638-a715-420a-8f4c-fb4730f2df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch=pc.from_texts([t.page_content for t in text_chunks], embedding, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82297457-c0cd-4636-b0bd-71ed40428523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33477afa-286b-47fa-ad05-03103810b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in zip(range(len(text_chunks)), text_chunks):\n",
    "   query_result = embeddings.embed(t.page_content)\n",
    "   index.upsert(\n",
    "   vectors=[\n",
    "        {\n",
    "            \"id\": str(i),  # Convert i to a string\n",
    "            \"values\": query_result, \n",
    "            \"metadata\": {\"text\":str(text_chunks[i].page_content)} # meta data as dic\n",
    "        }\n",
    "    ],\n",
    "    namespace=\"real\" \n",
    ")\n",
    "\n",
    "\n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418055c-458e-47c0-82e5-658da2ce868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af86337-50ea-4b1a-8ddf-dbd13dcc1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab502769-848c-449a-b0f4-994912b5cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f173361-01bb-4be8-abd4-8067270e9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6312a09-be51-44ed-ad25-5bcaff8f53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442af6b5-0f22-4aed-a00a-f96e3a3f5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d3a8b3-1ac4-4d29-8c39-69e7a5cded7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import chromadb\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb42d46-239d-4d11-bf4c-0bd328260c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(file_path):\n",
    "    pdf_file = open(file_path, 'rb')\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page_num in range( len(pdf_reader.pages)):\n",
    "        text += pdf_reader.pages[page_num].extract_text()\n",
    "    pdf_file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3f1148-6684-4755-8d77-3d9cfb1ae499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "    api_key=\"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\",\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58aa4bc8-1c0f-4759-8390-f2b3deff3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c90f35a-2dff-4160-a830-59e68417dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"Vector/db\")\n",
    "collection = client.create_collection(name=\"m_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0762a9e-8c26-4bae-b83a-713f26a472d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('Vector/pdfs'):\n",
    "    if filename.endswith('.pdf'):\n",
    "        # Convert PDF to text\n",
    "        loader=PyPDFDirectoryLoader(\"Vector/pdfs\")\n",
    "        data = loader.load()\n",
    "        # Split text into chunks\n",
    "        chunks = text_splitter.split_documents(data)\n",
    "\n",
    "        # Convert chunks to vector representations and store in Chroma DB\n",
    "documents_list = []\n",
    "embeddings_list = []\n",
    "ids_list = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    text_content = str(chunk)\n",
    "    vector = embeddings.embed_query(text_content)\n",
    "    \n",
    "    documents_list.append(text_content)\n",
    "    embeddings_list.append(vector)\n",
    "    ids_list.append(f\"{filename}_{i}\")\n",
    "\n",
    "collection.add(\n",
    "    embeddings=embeddings_list,\n",
    "    documents=documents_list,\n",
    "    ids=ids_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f9c0f-569d-4db5-8be0-b3809d363404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e9f014-4f01-4856-848c-0ec410a92824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6c3e7c-4564-4dfb-947c-5475b188c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if isinstance(chunk, str):\n",
    "        text_content = chunk\n",
    "    elif hasattr(chunk, 'text'):  # Check if the object has a 'text' attribute\n",
    "        text_content = chunk.text\n",
    "    else:\n",
    "        # Handle other cases where the chunk is not a string and doesn't have a 'text' attribute\n",
    "        continue\n",
    "    \n",
    "    vector = embeddings.embed_query(text_content)\n",
    "    embeddings_list.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d5221-990b-4ec5-854f-847195e5a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44542098-57f2-471e-ab4e-a1fed674a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"Vector/db\")\n",
    "collection = client.get_collection(name=\"m_collection\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e4294de-99df-4fca-b492-81371a96d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f4af7bb-a9f0-41cf-a6c7-1c5191afbf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  draw a picture of the evolving landscape of cryptocurrency price forecasting\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your query: \")\n",
    "query_vector = embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e20bc033-d86f-40f4-a19b-2fe8965ef573",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(query_embeddings=query_vector, n_results=2 , include=[\"documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8630e25-eab8-4ccd-ae88-941a558ff090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['crypto forecasting.pdf_219', 'crypto forecasting.pdf_203']], 'distances': None, 'metadatas': None, 'embeddings': None, 'documents': [[\"page_content='Kate Murray, Andrea Rossi, Diego Carraro, and Andrea Visentin. On forecasting cryptocurrency prices: A comparison\\\\nof machine learning, deep learning, and ensembles. Forecasting , 5:196–209, 01 2023. doi:10.3390/forecast5010010.\\\\nMuhammed Rafi, Qublai Ali Khan Mirza, Muhammad Izaan Sohail, Maria Aliasghar, Arisha Aziz, and Sufian\\\\nHameed. Enhancing cryptocurrency price forecasting accuracy: A feature selection and weighting approach' metadata={'source': 'Vector\\\\\\\\pdfs\\\\\\\\crypto forecasting.pdf', 'page': 23}\", \"page_content='Forecasting Cryptocurrency Prices Using Deep Learning: Integrating Financial, Blockchain, and Text Data\\\\nReferences\\\\nMark T. Leung, Hazem Daouk, and An-Sing Chen. Forecasting stock indices: a comparison of classification and level\\\\nestimation models. International Journal of Forecasting , 16:173–190, 04 2000. doi:10.1016/s0169-2070(99)00048-5.\\\\nFernando Ferraz and Vanesa Moura. A bayesian model for multiple change point to extremes, with application to' metadata={'source': 'Vector\\\\\\\\pdfs\\\\\\\\crypto forecasting.pdf', 'page': 22}\"]], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0609a91c-9067-4711-9944-bd0f6de911f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fabd200e-eed0-4d84-845a-35575815ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: [['crypto forecasting.pdf_201', 'crypto forecasting.pdf_140']]\n",
      "distances: None\n",
      "metadatas: None\n",
      "embeddings: None\n",
      "documents: [[\"page_content='interprets market sentiment expressed through text that extends beyond mere positivity or negativity. Furthermore,\\\\nfine-tuning an LLM on the target variable results in considerable improvement in forecasting performance compared to\\\\nmodels without NLP. This is the case even though the task of predicting price movements is far more abstract than\\\\ntraditional sentiment analysis.\\\\nNevertheless, our results indicate that pre-trained models deliver comparable, if not superior, results to fine-tuned' metadata={'source': 'Vector\\\\\\\\pdfs\\\\\\\\crypto forecasting.pdf', 'page': 21}\", \"page_content='One observation that deserves a special mention relates to the performance comparison between pre-trained and\\\\nfine-tuned models. The pre-trained NLP models, despite not being tailored to our dataset, yield greater benefits than\\\\nthose of the fine-tuned LLM. This insight underscores the potential of transfer learning in the domain of financial\\\\nforecasting.\\\\nFigure 5.2: Comparison of MLP profit and AUC ROC by target variable' metadata={'source': 'Vector\\\\\\\\pdfs\\\\\\\\crypto forecasting.pdf', 'page': 15}\"]]\n",
      "uris: None\n",
      "data: None\n"
     ]
    }
   ],
   "source": [
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169f01dd-b681-44f0-89dd-061bc8df9289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"page_content='interprets market sentiment expressed through text that extends beyond mere positivity or negativity. Furthermore,\\\\nfine-tuning an LLM on the target variable results in considerable improvement in forecasting performance compared to\\\\nmodels without NLP. This is the case even though the task of predicting price movements is far more abstract than\\\\ntraditional sentiment analysis.\\\\nNevertheless, our results indicate that pre-trained models deliver comparable, if not superior, results to fine-tuned' metadata={'source': 'Vector\\\\\\\\pdfs\\\\\\\\crypto forecasting.pdf', 'page': 21}\", \"page_content='One observation that deserves a special mention relates to the performance comparison between pre-trained and\\\\nfine-tuned models. The pre-trained NLP models, despite not being tailored to our dataset, yield greater benefits than\\\\nthose of the fine-tuned LLM. This insight underscores the potential of transfer learning in the domain of financial\\\\nforecasting.\\\\nFigure 5.2: Comparison of MLP profit and AUC ROC by target variable' metadata={'source': 'Vector\\\\\\\\pdfs\\\\\\\\crypto forecasting.pdf', 'page': 15}\"]]\n"
     ]
    }
   ],
   "source": [
    "print(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c034c298-1e40-471c-ac11-f389e8fa33ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\"page_content=\\'Kate Murray, Andrea Rossi, Diego Carraro, and Andrea Visentin. On forecasting cryptocurrency prices: A comparison\\\\\\\\nof machine learning, deep learning, and ensembles. Forecasting , 5:196\\\\u2013209, 01 2023. doi:10.3390/forecast5010010.\\\\\\\\nMuhammed Rafi, Qublai Ali Khan Mirza, Muhammad Izaan Sohail, Maria Aliasghar, Arisha Aziz, and Sufian\\\\\\\\nHameed. Enhancing cryptocurrency price forecasting accuracy: A feature selection and weighting approach\\' metadata={\\'source\\': \\'Vector\\\\\\\\\\\\\\\\pdfs\\\\\\\\\\\\\\\\crypto forecasting.pdf\\', \\'page\\': 23}\", \"page_content=\\'Forecasting Cryptocurrency Prices Using Deep Learning: Integrating Financial, Blockchain, and Text Data\\\\\\\\nReferences\\\\\\\\nMark T. Leung, Hazem Daouk, and An-Sing Chen. Forecasting stock indices: a comparison of classification and level\\\\\\\\nestimation models. International Journal of Forecasting , 16:173\\\\u2013190, 04 2000. doi:10.1016/s0169-2070(99)00048-5.\\\\\\\\nFernando Ferraz and Vanesa Moura. A bayesian model for multiple change point to extremes, with application to\\' metadata={\\'source\\': \\'Vector\\\\\\\\\\\\\\\\pdfs\\\\\\\\\\\\\\\\crypto forecasting.pdf\\', \\'page\\': 22}\"]]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(results[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f13380-5b33-4842-b22f-513947157e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
